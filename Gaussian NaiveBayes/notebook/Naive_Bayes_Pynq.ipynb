{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HARDWARE ACCELERATED MACHINE LEARNING LIBRARY\n",
    "# Classifying Handwritten Digits with Gausian Naive Bayes\n",
    "\n",
    "\n",
    "\n",
    "In this notebook a Gausian Naive Bayes application is executed locally, using our HW accelerated Machine Learning library (mllib_accel). We are given the option to choose between an accelerated execution that uses both software and hardware and a non-accelerated one, that uses only the CPU cores.\n",
    "\n",
    "Upon choosing the accelerated option, the accelerator's library is invoked, which is using Xilinxâ€™s built-in modules and classes, in order to drive the Programmable Logic. The Gausian Naive Bayes overlay that is used has been created with a custom accelerator (NB_training_kernel and NB_prediction_kernel), that receives data from Python, processes it, and returns the results, using AXI4-Stream Accelerator Adapter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Introduction\n",
    "\n",
    "The data are taken from the famous MNIST dataset.\n",
    "\n",
    "The original data file contains gray-scale images of hand-drawn digits, from zero through nine. Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "In this example the data we use are already preprocessed/normalized using Feature Standardization method (Z-score scaling).\n",
    "\n",
    "The data sets (train, test) have 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the (rescaled) pixel-values of the associated image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import cffi\n",
    "spark_home = os.environ.get(\"SPARK_HOME\", None)\n",
    "\n",
    "# Add the spark python sub-directory to the path\n",
    "sys.path.insert(0, spark_home + \"/python\")\n",
    "\n",
    "# Add the py4j to the path.\n",
    "# You may need to change the version number to match your install\n",
    "sys.path.insert(0, os.path.join(spark_home + \"/python/lib/py4j-0.10.7-src.zip\"))\n",
    "\n",
    "# Initialize PySpark to predefine the SparkContext variable 'sc'\n",
    "filename = spark_home+\"/python/pyspark/shell.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* NaiveBayes Application *\n",
      " # train file:               inputs/MNIST_2k.dat\n",
      " # test file:                inputs/MNIST_2k.dat\n"
     ]
    }
   ],
   "source": [
    "    dataset = \"MNIST\"\n",
    "    decision = 1\n",
    "    _accel_ = 1\n",
    "    \n",
    "    train_file = \"inputs/\" + dataset + \"_2k.dat\"\n",
    "    test_file = \"inputs/\" + dataset + \"_2k.dat\"\n",
    "\n",
    "    with open(dataset, 'r') as f:\n",
    "        for line in f:\n",
    "            if line[0] != '#':\n",
    "                parameters = line.split(',')\n",
    "                numClasses = int(parameters[0])\n",
    "                numFeatures = int(parameters[1])\n",
    "    f.close()       \n",
    "\n",
    "    print(\"* NaiveBayes Application *\")\n",
    "    print(\" # train file:               {:s}\".format(train_file))\n",
    "    print(\" # test file:                {:s}\".format(test_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SW-only vs HW accelerated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select mode (0: SW-only, 1: HW accelerated): 1\n"
     ]
    }
   ],
   "source": [
    "_accel_ = int(input(\"Select mode (0: SW-only, 1: HW accelerated): \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "def parsePoint(line):\n",
    "    \"\"\"\n",
    "    Parse a line of text into an MLlib LabeledPoint object.\n",
    "    \"\"\"\n",
    "\n",
    "    data = [float(s) for s in line.split(',')]\n",
    "\n",
    "    return LabeledPoint(data[0], data[1:])\n",
    "\n",
    "trainSet = []\n",
    "with open(train_file, 'r') as f:\n",
    "    for line in f:\n",
    "        trainSet.append(parsePoint(line))\n",
    "f.close()\n",
    "\n",
    "testSet = []\n",
    "with open(test_file, 'r') as f:\n",
    "    for line in f:\n",
    "        testSet.append(parsePoint(line))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Model NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* NaiveBayes Training *\n",
      "     # numBuffers:               1\n",
      "     # numClasses:               10\n",
      "     # numFeatures:              784\n",
      "     # Accelerated:              True\n",
      "! Time running Naive Bayes train in hardware: 0.617 sec\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib_accel.classificationNB_Pynq import Naivebayes\n",
    "from sys import argv\n",
    "from time import time\n",
    "\n",
    "\n",
    "NB = Naivebayes(numClasses, numFeatures, decision)\n",
    "\n",
    "start = time()\n",
    "\n",
    "# Train a Naive Bayes model given an dataset of (label, features) pairs. \n",
    "NB.train(trainSet, _accel_)\n",
    "\n",
    "end = time()\n",
    "\n",
    "if _accel_:\n",
    "    print(\"! Time running Naive Bayes train in hardware: {:.3f} sec\".format(end - start))\n",
    "else:\n",
    "    print(\"! Time running Naive Bayes train in software: {:.3f} sec\".format(end - start))\n",
    "\n",
    "stats = [\"Means\",\"Variances\",\"Priors\"]\n",
    "for i in range (3):\n",
    "    NB.save(\"outputs/trainPack\"+ stats[i] + \".txt\", i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction with NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* NaiveBayes Testing *\n",
      "     # accuracy:                 0.754 (1509/2000)\n",
      "     # true:                     1509\n",
      "     # false:                    491\n",
      "! Time running Naive Bayes test in harware: 2.698 sec\n"
     ]
    }
   ],
   "source": [
    "start = time()    \n",
    "NB.test(testSet,_accel_)    \n",
    "end = time()\n",
    "print(\"! Time running Naive Bayes test in harware: {:.3f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics\n",
    "We present execution time measurements in different target devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Target | Function | Time |\n",
    "| --- | --- | --- |\n",
    "| PYNQ SW-only: | Training | 65 sec |\n",
    "| PYNQ SW-only: | Prediction | 843 sec |\n",
    "| Intel Core i5: | Training | 4.5 sec |\n",
    "| Intel Core i5: | Prediction | 66 sec |\n",
    "| PYNQ HW accelerated: | Training | 0.63 sec |\n",
    "| PYNQ HW accelerated: | Prediction | 2.7 sec |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
